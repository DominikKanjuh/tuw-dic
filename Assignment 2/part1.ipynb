{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c883cf-e068-4729-b59e-a22f45339837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.rdd import RDD\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1e1ec4-44c1-43ba-ab61-d8ead487310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/10 22:05:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DIC\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e7ffb-32ed-4495-bd42-548c3210f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\")\n",
    "reviews = df.rdd.filter(lambda row: row[\"reviewText\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad10615-f230-40a7-898b-52acf9588307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.select(\"category\", \"reviewText\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d79f42-b916-4651-83b0-d9cce1420cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = sc.broadcast(set(spark.sparkContext.textFile(\"stopwords.txt\").collect()))\n",
    "TOKEN_REGEX = re.compile(r\"[\\s\\t\\d()\\[\\]{}.!?,;:+=\\-_\\\"'`~#@&*%€$§\\\\/]+\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return set(\n",
    "        token for token in TOKEN_REGEX.split(text.lower())\n",
    "        if len(token) > 1 and token not in stopwords.value\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7bb7d-ca89-4864-abf6-3d7e094f46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) (category, reviewText)\n",
    "cat_text = reviews.map(lambda row: (row[\"category\"], row[\"reviewText\"]))\n",
    "\n",
    "# (2) ((term, category), 1)\n",
    "term_cat_pairs = cat_text.flatMap(lambda x: [((term, x[0]), 1) for term in tokenize(x[1])])\n",
    "\n",
    "# (3) \n",
    "term_cat_counts = term_cat_pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# (4) \n",
    "term_grouped = term_cat_counts.map(lambda x: (x[0][0], (x[0][1], x[1]))).groupByKey()\n",
    "\n",
    "# (5) \n",
    "docs_per_cat = cat_text.map(lambda x: (x[0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "total_docs = docs_per_cat.values().sum()\n",
    "\n",
    "docs_per_cat_bc = sc.broadcast(dict(docs_per_cat.collect()))\n",
    "total_docs_bc = sc.broadcast(total_docs)\n",
    "\n",
    "# (6) \n",
    "global_term_counts = term_cat_pairs.map(lambda x: (x[0][0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "global_term_counts_bc = sc.broadcast(dict(global_term_counts.collect()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc7729-db36-4502-9a41-07a79ef57245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) \n",
    "def compute_chi(term, cat_counts_iter):\n",
    "    cat_counts = dict(cat_counts_iter)\n",
    "    df_t = global_term_counts_bc.value.get(term, 0)\n",
    "    N = total_docs_bc.value\n",
    "    results = []\n",
    "\n",
    "    for cat in docs_per_cat_bc.value:\n",
    "        A = float(cat_counts.get(cat, 0))\n",
    "        B = df_t - A\n",
    "        C = docs_per_cat_bc.value[cat] - A\n",
    "        D = N - A - B - C\n",
    "        denom = (A + C) * (B + D) * (A + B) * (C + D)\n",
    "        chi2 = N * ((A * D - B * C) ** 2) / denom if denom > 0 else 0.0\n",
    "        results.append(((term, cat), chi2))\n",
    "    return results\n",
    "\n",
    "chi_squares = term_grouped.flatMap(lambda x: compute_chi(x[0], x[1]))\n",
    "chi_squares.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c83b0-6ab6-47d4-ba75-e47b7f2ce8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8)\n",
    "by_category = chi_squares.map(lambda x: (x[0][1], (x[1], x[0][0])))\n",
    "top75 = by_category.groupByKey().mapValues(\n",
    "    lambda values: sorted(values, reverse=True)[:75]\n",
    ").collect()\n",
    "\n",
    "# (9)\n",
    "formatted = []\n",
    "for category, top_terms in sorted(top75):\n",
    "    terms = \" \".join([f\"{term}:{score}\" for score, term in top_terms])\n",
    "    formatted.append(f\"<{category}> {terms}\")\n",
    "\n",
    "# (10) \n",
    "all_terms = sorted(set(term for _, terms in top75 for _, term in terms))\n",
    "print(all_terms[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c879f-8393-425e-a68b-c39418b898c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) \n",
    "with open(\"output_rdd.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in formatted:\n",
    "        f.write(line + \"\\n\")\n",
    "    f.write(\" \".join(all_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5263d39-8fb3-432f-9eb4-2a450b37ad78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
