{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2e9dce-d3fd-4f19-a5d2-cd670d974c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer, StopWordsRemover, CountVectorizer, IDF,\n",
    "    ChiSqSelector, StringIndexer, Normalizer\n",
    ")\n",
    "from pyspark.ml.classification import (LinearSVC, OneVsRest)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720bd99-4b9d-4eb4-9ea0-004e12253adc",
   "metadata": {},
   "source": [
    "Starting Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cbab26-1075-487b-b71b-9cdef794f756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/11 00:03:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"TFIDF_pipeline\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b949d-c1c6-42ae-9bb7-044dab6c6fc4",
   "metadata": {},
   "source": [
    "Importing dataset, stopwords and delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a044cb77-79b4-4f17-864f-0e65a8545249",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "delimiters = r\"\"\"[ \\t\\n\\d\\(\\)\\[\\]\\{\\}\\.\\!\\?,;:\\+=\\-_\\\"'`~#@&\\*\\%€\\$§\\\\/]+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dac47e-2697-4d68-b0b8-2f23ba73a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(dataset_path)\n",
    "df = df.select(\"reviewText\", \"category\")\n",
    "stopwords = set(open(\"stopwords.txt\").read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4572d02-14f4-4472-904f-120c356c19f3",
   "metadata": {},
   "source": [
    "Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cedfed7e-9b05-4b10-8d1e-a9dd1efc5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"reviewText\",\n",
    "    outputCol=\"terms\",\n",
    "    pattern=delimiters,\n",
    "    toLowercase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62bb09-80ed-4c88-b831-030d29626890",
   "metadata": {},
   "source": [
    "Stopwords Removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e82644-348e-4dff-9d9a-f1f9dd3999b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(\n",
    "    inputCol = \"terms\",\n",
    "    outputCol = \"terms_clean\",\n",
    "    stopWords = list(stopwords)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d3cc1-cd0f-4ede-a89d-02cb4b6c16de",
   "metadata": {},
   "source": [
    "TF_IDF Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326fa3d9-e6a9-4d83-befb-50b9574fac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency\n",
    "c_vec = CountVectorizer(\n",
    "    inputCol=\"terms_clean\", \n",
    "    outputCol=\"rawFeatures\"\n",
    ")\n",
    "\n",
    "# Inverse Document Frequency\n",
    "idf = IDF(inputCol=\"rawFeatures\", \n",
    "          outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e1b52-59c1-4c20-82be-69f33fe98b60",
   "metadata": {},
   "source": [
    "Chi-square Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb676e9-312e-4225-9804-0f5c8fdc911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting category column to numerical values using StringIndexer\n",
    "label_indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "\n",
    "selector = ChiSqSelector(\n",
    "    numTopFeatures=2000,\n",
    "    featuresCol=\"features\",\n",
    "    outputCol=\"selectedFeatures\",\n",
    "    labelCol=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d67a3-a124-4dd3-bf5b-bbf86af8cabd",
   "metadata": {},
   "source": [
    "Combining everything into Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826c38e4-f5e0-46f3-a482-19adea0a17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        tokenizer,\n",
    "        remover,\n",
    "        c_vec,\n",
    "        idf,\n",
    "        label_indexer,\n",
    "        selector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8deeed1-e817-40ed-bbc6-2b9c65e175fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df)\n",
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3cf64c-e7db-41bf-a9f4-dc69982da5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV model - third in the Pipeline stage.\n",
    "cv_model = model.stages[2]\n",
    "vocab = cv_model.vocabulary\n",
    "\n",
    "# Selector model - sixth in the Pipeline stage.\n",
    "selector_model = model.stages[5]\n",
    "selected_indices = selector_model.selectedFeatures\n",
    "\n",
    "selected_terms = [vocab[i] for i in selected_indices]\n",
    "\n",
    "with open(\"output_ds.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for term in sorted(selected_terms):\n",
    "        f.write(term + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9ab66-cc17-492f-a20c-4d43330f535a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8d7b04",
   "metadata": {},
   "source": [
    "# Part 3: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab73a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalization\n",
    "normalizer = Normalizer(inputCol=\"selectedFeatures\", outputCol=\"normalizedFeatures\", p=2.0)\n",
    "\n",
    "# Classifier\n",
    "svm = LinearSVC(featuresCol=\"normalizedFeatures\", labelCol=\"label\")\n",
    "ovr = OneVsRest(classifier=svm, featuresCol=\"normalizedFeatures\", labelCol=\"label\")\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        tokenizer,\n",
    "        remover,\n",
    "        c_vec,\n",
    "        idf,\n",
    "        label_indexer,\n",
    "        selector,\n",
    "        normalizer,\n",
    "        ovr\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid search\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(selector.numTopFeatures, [50, 2000]) \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(svm.maxIter, [10, 100]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Split data\n",
    "trainDF, valDF, testDF = df.randomSplit([0.7, 0.2, 0.1], seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bestModel = None\n",
    "bestF1    = 0.0\n",
    "\n",
    "for params in param_grid:\n",
    "    # copy pipeline & apply this set of hyper-params\n",
    "    model = pipeline.copy(params).fit(trainDF)\n",
    "    f1    = evaluator.evaluate(model.transform(valDF))\n",
    "    if f1 > bestF1:\n",
    "        bestF1, bestModel = f1, model\n",
    "\n",
    "print(\"Best F1 on validation set:\", bestF1)\n",
    "\n",
    "# now test‐set performance\n",
    "testPreds = bestModel.transform(testDF)\n",
    "testF1    = evaluator.evaluate(testPreds)\n",
    "print(\"F1 on test set:\", testF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98450724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
